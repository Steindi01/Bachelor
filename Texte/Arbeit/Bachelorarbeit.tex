\documentclass{scrartcl}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{tabularx}
 
\title{Messungen und Vergleich von Virtualisierungsumgebungen}
\subtitle{Bachelorarbeit}
\author{Christoph Steindl}
\date{\today}
\begin{document}
 
\maketitle
\tableofcontents

\newpage
\lstset{language=python, 
						basicstyle=\small, 
						tabsize=2,
						showspaces=false,
						showstringspaces=false,
						numbers = left}
\section{Einleitung}
\subsection{Aufgabenstellung}
Das Thema dieser Arbeit "`Messungen und Vergleich von Virtualisierungsumgebungen"' beinhaltet schon in seinem Titel eine der zentralen Komponenten dieser Arbeit, nämlich den Begriff der "`Virtualisierung"'. In größeren Firmen ist es schon gängige Praxis nicht mehr für jeden Mitarbeiter einen eigenen vollwertigen PC zu kaufen, sondern man steigt um auf so genannte "`Slim Clients"'. Diese Clients dienen als Schnittstelle zwischen dem Mitarbeiter der Firma und der virtuellen Instanz eines Betriebssystems, welches auf einem Server läuft. Da man einen geringeren finanziellen Aufwand mit virtuellen Umgebungen, Instanzen und Systemen hat, ist diese Praxis auch im Privatbereich verbreitet.
Doch muss natürlich auch hier garantiert werden, dass die Virtualisierung von beliebigen Komponenten fair abläuft, also dass es keine Bevorzugung von einzelnen Komponenten gegenüber anderen gibt. Auch wenn man diese Fairness natürlich auch auf einer sehr Hardware-Nahen Ebene testen könnte, wird in der folgenden Arbeit vor allem auf virtuelle Maschinen, also Betriebssysteme, welche auf virtuellen Hardware-Komponenten basieren, eingegangen. Um diese Fairness gewährleisten zu können, gilt es ein Framework zu erstellen, mit dem Aussagen über die Gleichbereichtigung einzelner virtueller Maschinen gemacht werden können. Neben der Implementierung des Frameworks ist auch das Ausführen von Tests und deren Analyse teil dieser Arbeit. Zusätzliche Anforderungen sind eine möglichst hohe Portabilität zu erreichen, sodass das Framework möglichst auf allen System eingesetzt werden kann und den Aufwand des Testers/Users, der die Tests durchführen will zu minimieren. Es soll also darauf hinauslaufen, dass möglichst große Teile des Frameworks automatisch ablaufen können.

\newpage
\section{Virtuelle Maschinen}
Dass das Erstellen von virtuellen Maschinen nicht nur ein kurzfristiges Phänomen ist, zeigt wahrscheinlich am allerdeutlichsten, dass große IT-Firmen jeweils ihre eigenen Programme zur Erstellung ebendieser implementiert haben, beziehungsweise jeweils eigene Hypervisor zur Verfügung stellen. Aber auch die Open-Source-Community hat mit dem Projekt Xen Hypervisor das Thema der Virtualisierung aufgegriffen, welches unter der GPL-Lizenz frei verfügbar ist. Eine Auflistung einiger Virtualisierungsprojekte von unterschiedlichen Firmen ist in Tabelle \ref{tab:Hypervisor} zu finden. Aber auch ein Großunternehmen wie IBM setzt, auch wenn nicht eigens eine Software implementiert auf Virtualisierung, wie die enge Integration anderer Virtualisierungsumgebungen in \cite{IBMSystems.2005}
\begin{table}[tbp]
	\centering
		\begin{tabular}{ c | c }
			Hypervisor & zugehörige Firmen \\
			\hline
			Oracle VM VirtualBox \cite{VBox} & Oracle\\
			Windows Virtual PC \cite{Mic} & Microsoft\\
			Xen Hypervisor \cite{Xen}& Citrix Systems, Inc.\\
			VMware \cite{VMware}& VMware, Inc.
		\end{tabular}
	\caption{Liste unterschiedlicher Hypervisor}
	\label{tab:Hypervisor}
\end{table}
\subsection{Virtualisierung}
Den Begriff "`Virtualisierung"' darf man allerdings nicht erst bei den hardwarefernen virtuellen Maschinen beginnen lassen. 
\subsubsection{Vorteile Virtualisierung/Wieso VM}
\subsubsection{Scheduling}
Jeder Hypervisor einer virtuellen Maschine muss ein Scheduling betreiben, mit dem er Ressourcen den einzelnen virtuellen Maschinen zuweisen kann. Dieses Scheduling-Verfahren kann in der Norm zweierlei Qualitätskriterien erfüllen:
\begin{itemize}
	\item Maximale Auslastung: Oberstes Ziel ist es, dass soviel Durchsatz auf den einzelnen Hardwarekomponenten wie möglich erzeugt wird. Dies bedeutet, dass beispielsweise die CPU immer ausgelastet sein sollte, auch wenn nicht immer alle Instanzen einer virtuellen Maschine gleich behandelt werden.
	\item Maximale Fairness: Hier sollen alle Instanzen gleich behandelt werden. Es kann in diesem Fall auch dazu kommen, dass gewisse Komponenten Leerlaufzeiten haben, obwohl eigentlich Aufträge für diese bereit wären.
\end{itemize}
Auch wenn hier die Rede von virtuellen Maschinen ist, so kann man obige Überlegung auf jederlei Schedulingmechanismus übertragen.
\subsection{Aufbau einer Virtuellen Maschine}
Um eine virtuelle Maschine einrichten zu können, bedarf es meherer Komponenten:
\begin{itemize}
	\item Hardware: Auf den Hardwarekomponenten werden alle Vorgänge, welche in einer Virtuellen Maschine vorgehen, tatsächlich ausgeführt.
	\item VMM (Virtual Machine Monitor)/Hypervisor: Der VMM regelt die Kommunikation zwischen der Hardware und den virtuellen Maschinen. der VMM legt für die einzelnen virtuellen Maschinen virtuelle Ressourcen an, welche diese dann verwenden können. Es wird zwischen zwei Typen an VMM unterschieden\cite{IBMSystems.2005}:
	\begin{itemize}
		\item Type 1: Der VMM wird direkt auf der Hardware betrieben.
		\item Type 2: Der VMM wird innerhalb des existierenden Betriebssystems installiert. Dieses funktioniert weiterhin ohne Einschränkungen und die Kommunikation mit der Hardware wird über dieses so genannte Host-Betriebssystem geregelt.
		\item Hybrid: \cite{Abramson.2006} erweitert diese Typen und sprechen von einem Hybriden-Ansatz, nur aus einem kleinen Hypervisor besteht, welcher nur CPU und Speicher verwaltet, während I/O von den nativen Treibern eines Service-Betriebssystems geregelt werden.
	\end{itemize}
	\item VM (Virtual Machine): Die VM besteht aus den Komponenten, welche von dem VMM für sie angelegt wurden. Diese Komponenten können ganz unterschiedliche Spezifikationen, als die der "`echten"' Hardware haben, indem sie vom VMM emuliert werden.
	\item Guest-Betriebssystem: Innerhalb der VM muss wiederum zur Kommunikation mit der virtuellen Hardware ein weiteres Betriebssystem installiert werden. Dieses kann beliebig gewählt werden, da es vom Host-Betriebssystem vollkommen abgekapselt ist. 
\end{itemize}

\newpage
\section{Architektur}
\subsection{Design}
Ein solches Projekt beginnt man klein und versucht es dann nach außen hin zu vergrößern. So war es auch hier und so mussten zuerst Überlegungen über den Aufbau angestellt werden. Es gibt hier zweierlei Herangehensweisen, um zu den gewünschten Ergebnissen zu kommen:
\begin{itemize}
	\item Sequentiell: Es ist möglich einen Test für eine virtuelle Maschine zu erstellen. Dieser wird auf ebendieser ausgeführt und durch eine Vielzahl an Tests mit unterschiedlichen Konfigurationen kann man einen Schluss über das Gesamtsystem ziehen. Hier ist wichtig, dass die Tests nacheinander ausgeführt werden, damit sie sich untereinander nicht beeinträchtigen.
	\item Synchron: Es laufen mehrere virtuelle Maschinen, auf welchen jeweils der selbe Test ausgeführt wird. Hier stehen die VMs kompetativ zueinander und man kann direkt ablesen, welche VM in einem gewissen Zeitabschnitt eine bessere Performance gezeigt hat. Die Synchronität des Systems gelingt natürlich immer nur innerhalb gewisser (Rand-)Bedingungen, welche physikalischer Natur sind, weshalb  es schwieriger ist, ein synchrones System zu implementieren.
\end{itemize}
Die Entscheidung wurde für System, das zumeist im synchronen Betrieb laufen soll, gefällt, trotzdem wird der sequentielle Betrieb aber unterstütz. Diese Entscheidung ist allerdings gleichzeitig ein Indikator für die Architektur des Frameworks. Muss man Prozesse synchron halten, so empfiehlt es sich eine Instanz zu implementieren, welche als Monitor fungiert. Diese Instanz hat im Idealfall mit den einzelnen virtuellen Maschinen nichts zu tun und kümmert sich nur darum, wann welche Kommandos für welche Prozesse an die virtuellen Maschinen erteilt werden. Da der Monitor unabhängig sein soll, hat sich auch der Platz, wo dieser ausgeführt wird empfohlen. Man kann diesen einfach im Host-Betriebssystem ausführen und jede einzelne virtuelle Maschine verbindet sich mit diesem. Man kann also sagen, dass das Framework eine Client-Server-Architektur beinhaltet.

Nachdem diese Entscheidung gefallen war, standen als nächstes einige Überlegungen zur Kommunikation zwischen dem Client und dem Server an. Es stellte sich die Frage, wie groß der Kommunikationsaufwand ist und wie dieser bewältigt werden solle. Da sich der Aufwand wahrscheinlich in Grenzen hält, fiel die Entscheidung auf eine Kommunikation mit TCP. Weil nur kleine Datenmengen, wie Steuerdaten und kleine Dateien, über die Netzwerkschnittstellen von beiden Seiten gesendet werden, erhielt dieses Protokoll, zu Gunsten der Verbindungssicherheit von TCP, da bei UDP immer mit Datenverlust gerechnet werden muss, den Vorzug.

In Folge dieser Entscheidung kristallisierte sich auch nach und nach ein Favorit bezüglich Programmiersprache heraus. Der gute und einfach zu handhabende Socket-Support in Python erwies sich als gelegen und in Verbindung mit der einfachen Istallation (bzw. der standardmäßigen Vorinstallation in einigen Betriebssystemen) wurde Python als Implementierungssprache festgelegt. Das Framework soll möglichst vielseitig, also für möglichst jede Art von VMM, VM und Betriebssystem, einsetzbar sein, weshalb Portabilität eine wesentliche Rolle für das Framework spielt. Daher wurde versucht im Folgenden möglichst mit der Standardbibliothek aus Python in der Implementierung auszukommen, um den Installationsaufwand möglichst gering zu halten.

Einzig, wie und was getestet werden soll musste noch festgelegt werden. Aber auch hier fanden sich schnell zwei Gebiete, auf die näher eingegangen werden sollten. Einerseits sollte die Zuweisung der Rechenleistung und der Speicherzuteilung genauer unter die Lupe genommen werden, andererseits ist die erreichbare Performance bei hoher Netzlast wichtig. Es wurden Testszenarien in diesen Gebieten entwickelt, welche dann auf den virtuellen Maschinen verwendet werden können.
\subsection{Umsetzung}
Folgend wird auf die endgültige Implementation näher eingegangen. Das Framework reicht von der Abhandlung einzelner Tests bis hin zum Erstellen erster Grafiken und Messwerte, welche die zuvor ausgeführten Tests als Basis nehmen, welche später in dieser Arbeit in Abschnitt \ref{test} genauer beschrieben werden.
\subsubsection{Sequenzdiagramm}
Anhand des Sequenzdiagramms in Abbildung \ref{fig:SD} soll der Ablauf der des Frameworks nocheinmal veranschaulicht werden. Nachdem der Tester die Einstellungen für die Tests richtig getroffen hat startet er zuerst das Skript \textit{host.py} mit der Klasse \textit{Host} und danach auf jeder VM die Klasse das Skript \textit{client.py} mit der Klasse \textit{Client}. Der Client verbindet sich mit dem Host welcher dann das Ausführen des Tests initiiert. Der Test wird im Weiteren durchgeführt und eine Evaluation (sofern in der Konfiguration nicht anders vorgesehen) der Messwerte durchgeführt.
\paragraph{Anmerkung} Das Sequenzdiagramm wurde zur Veranschaulichung im Bereich des Ausführen eines Tests ("`4: run test"') vereinfacht. In Wirklichkeit bedarf es hier noch einer Kommunikation zwischen den beiden Instanzen, um zum Beispiel die einzelnen Iterationen synchron zu halten und die Beendigung eines Tests anzuzeigen.
\begin{figure}[ht]
	\centering
		\includegraphics[width=1.00\textwidth]{Bilder/SD.png}
	\caption{Die Abläufe zwischen der Klasse \textit{Host} und einer Klasse \textit{Client} dargestellt in einem Sequenzdiagramm}
	\label{fig:SD}
\end{figure}

\subsubsection{Aufbau der Architektur}
Wie bereits erwähnt, handelt es sich um eine Client-Server-Architektur. Es wird eine Instanz der Klasse \textit{Host} aufgerufen, welche auf einem beliebigen Rechner liegen kann. Innerhalb jeder virtuellen Maschine wird eine Instanz der Klasse \textit{Client} aufgerufen, welche sich mit dem Host verbindet (vgl. Abschnitt \ref{class}). Die Steuerkommunikation findet ausschließlich zwischen diesen beiden Instanzen statt. In Abbildung \ref{fig:CD} ist das Framework nochmals grafisch dargestellt. 

\begin{figure}[ht]
	\centering
		\includegraphics[width=1.00\textwidth]{Bilder/CD.png}
	\caption{Komponentendiagramm des Frameworks mit zwei virtuellen Maschinen}
	\label{fig:CD}
\end{figure}


\subsubsection{Klassen-, Datei-, Skriptbeschreibung}\label{class}
\paragraph{Host}
Die Klasse Host ist jene Klasse, welche auf dem Server gestartet werden soll. Sie muss mit folgenden drei Parametern initiiert werden:
\begin{itemize}
	\item Port to listen <int>: Es muss ein gewisser Port (TCP/IP-Model - Transport Layer) ausgewählt und deklariert werden, über den eine Verbindung zu dem Server hergestellt werden kann. Die Auswahl dazu sollte im Bereich der frei wählbaren Ports liegen und demnach größer als 1024 sein.
	\item Number of clients <int>: Hier wird vom Benutzer ausgewählt, wieviele Clients (also virtuelle Maschinen) sich mit dem Server verbinden sollten. Bevor besagte Anzahl nicht erreicht ist, werden die Tests nicht gestartet.
	\item Number of iterations <float>: Es wird angegeben, wie oft ein einzelner Testvorgang jeweils wiederholt werden soll.
\end{itemize}
Nachdem eine Instanz der Klasse aufgerufen wurde, wartet sie, dass sich die virtuellen Maschinen verbinden. Ist dies geschehen, beginnt sie eine Liste an Befehlen abzuarbeiten und diese den Clients mitzuteilen. Diese Liste wird von einer Konfigurationsdatei eingelesen und kann folgendes beinhalten:
\begin{itemize}\label{command}
	\item IO: Es wird ein Ein-Ausgabetest gestartet.
	\item Net: Es wird ein Netzwerktest gestartet.
	\item data: Die gesammelten Daten der Clients sollen an den Host geschickt werden.
	\item config: Eine Zusammenstellung der Konfiguration der virtuellen Maschinen (Größe Arbeitsspeicher, Prozessor, Betriebssystem) soll an den Host übermittlet werden.
	\item stopClient: Es wird der Befehl zum Stoppen der Clients an diese übertragen.
	\item plot: Aus den gesammelten Daten der Clients sollen Graphen erstellt werden.
\end{itemize}
Wird ein Test gestartet, so ist es weiters Aufgabe des Hosts die einzehlnen Iterationen synchron zu halten. Es wird für jede zu absolvierende Iteration des Clients ein "`iteration"'-Kommando gesendet, nach dessen Erhalt die Clients damit starten ihren Test durchzuführen. Sind alle Iterationen abgehandelt, wird das nächste Kommando aus der Liste abgearbeitet.
Im Falle von Netzwerktests und der Übermittlung von Daten (config, data) stellt der Server zwischen den Kommandos der Liste den Clients zusätzlich ein Socket zur Verfügung, um sich verbinden zu können.
\paragraph{Client}
Die Client-Klasse wird ebenfalls vom User aufgerufen und dieser Aufruf beinhaltet zwei Parameter:
\begin{itemize}
	\item Port to connect <int>: Hier muss der gleiche Port angegeben werden, wie beim Host, damit sich beide Einheiten über diesen Port verbinden können.
	\item Server IP <String>: Um den Port einer Maschine zuteilen zu können, muss ebenflass die IP-Adresse des Hosts angegeben werden. Es ist wichtig dabei die des richtigen Netzwerk-Interfaces zu wählen, welches mit dem Client verbunden ist. Da der Host potentiell auf derselben Maschine ausgeführt wird, wo auch der VMM installiert ist, besitzt sie in diesem Fall zumindest zwei Interfaces, nämlich ein reelles und ein virtuelles.
\end{itemize}
Die Client-Klasse verbindet sich also mit dem Host und erhält von diesem ihre Kommandos. Diese sind jeweils zu Paaren zusammengefasst und haben folgende Struktur: [Kommando, Zusatzinformation]. Diese Kommandos werden ausgelesen und dann jeweils abgearbeitet. Die Abarbeitung ist entweder das Durchführen eines Tests, oder das Senden von Information an den Host.
Die Testergebnisse werden in einer CSV-Date, welche mit einem Zeitsptempel versehen ist, abgespeichert, damit man die Rohdaten weiterhin besitzt, falls bei der späteren Übertragung Fehler geschehen.
\paragraph{Enum}
Die zuvor genannten Klassen können ebenfalls eine Enum-Klasse generieren. Diese Klasse enthält keine Methoden, sondern nur Membervariablen. Die Klasse ist ein Wörterbuch für die Kommunikation zwischen Host und Client, weshalb sie vor allem String-Variablen enthält, die gewisse Befehle bedeuten. Es können aber auch Konstanten, welche sowohl für die Server- als auch die Clientseite gelten definiert werden. Verwendet man dieses Enum hat dies zum Vorteil, dass man die Konstanten jeweils (seien es numerische Werte oder auch String-Variablen) nur einmal ändern muss und nicht bei jeder Klasse einzeln.
\paragraph{Results}
In der Klasse Results werden die gesammelten Werte-Tupel verwertet. Der Host erstellt, wenn in seiner Konfigurationsdatei "`data"' gesetzt ist, eine Datei mit dem Namen "`results.csv"' innerhalb eines Ordners mit dem aktuellen Zeitstempel. Dort sind die Ergebnisse aller Clients nacheinander gespeichert. Es wird dabei immer abgespeichert, um welchen Test es sich handelt und von welchem Client die Daten stammen. Die Datei wird also ausgelesen und mit den Werten danach Graphen erstellt. Um dieses Feature nutzen zu können müssen die Bibliotheken \textit{matplotlib}\footnote{siehe: http://matplotlib.sourceforge.net/} und \textit{NumPy}\footnote{siehe: http://numpy.scipy.org/} installiert sein. Es können hierbei folgende Formate ausgewählt werden.
\begin{itemize}
	\item \textit{scatter:} Bei diesem Format wird die Laufzeit der einzelnen Iterationen für alle Clients als Scatter-Plot aufgetragen.
	\item \textit{sum:} Hier wird die Laufzeit der einzelnen Iterationen jeweils summiert und dann wiederum gegen die Iterationen aufgetragen. Dies geschieht wieder für alle Clients in einem Plot.
	\item \textit{stats:} Es wird eine Datei mit dem Namen "`stats.csv"' in dem Ordner, welcher von der Host-Klasse mit dem Zeitstempel erstellt wurde, erzeugt. In dieser wird für jeden Client folgende statistische Information abgespeichert:
	\begin{itemize}
		\item Mean-Value: Der Mittelwert aller Iterationen
		\item Variance: Die Varianz aller Iterationen
		\item Std\_Variation: Die Standardabweichung berechnet aus der Varianz
		\item Maximum: Der Maximalwert aller Iterationen
		\item Minimum: Der Minimalwert aller Iterationen
		\item Sum: Die Summe aller Werten der Iterationen 
	\end{itemize}
	\item \textit{hist:} Es wird ein Histogramm erzeugt, dass die Verteilung aller Clients zeigt.
	\item \textit{scatter90:} Es wird ein Scatterplot erzeugt, bei dem alle Werte, welche zwischen $0.95*max\leq x \leq max$ und $0.95*max\geq x \geq max$ ignoriert werden. Dies dient dazu um Außreißer zu entfernen, die unter Umständen für das Messergebnis nicht relevant sind.
\end{itemize}
\paragraph{VBox.py}
Dieses Skript dient dazu, um bei der Verwendung von "`Oracle VM VirtualBox"' als VMM, die Abläufe automatisieren zu können. Das Skript ruft nicht nur die Client-Klasse innerhalb der virtuellen Maschine auf, sondern startet auch diese zuvor bziehungsweise beendet diese danach. In einer Schleife geschalten, können so ohne Zwischeneingabe des Benutzers Tests mit dem Ausführen von nur einem Skriptbefehl abgehandelt werden. Um dieses Skript verwenden zu können ist es notwendig die 
\begin{itemize}
	\item Name <String>: Als Unterscheidungsmerkmal zwischen den einzelnen virtuellen Maschinen dient in VirtualBox ein Name. Dieser muss beim Aufruf angegeben werden, um die richtige Maschine starten zu können.
	\item Path <String>: In der Path-Variable muss angegeben werden, wo sich in Bezug auf das virtuelle Dateisystem der virtuellen Maschine das Arbeitsverzeichnis des Frameworks liegt, damit einerseits von dort die Dateien des Frameworks aufgerufen werden können und andererseits Daten dorthin gespeichert werden können.
	\item Port to connect <int>: Analog wie beim Einzelaufruf muss auch hier ein Port angegeben werden. Geschieht dies nicht, so wird ein Standardport (50007) verwendet.
	\item Server IP <String>: Analog wie beim Einzelaufruf muss auch hier eine IP-Adresse angegeben werden. Geschieht dies nicht, so wird die IP-Adresse des Systems, auf dem das Skript gestartet wird herausgefunden und dafür verwendet.
\end{itemize}
Um dieses Skript einsetzen zu können ist die Installation der VirtualBox-SDK Voraussetzung. Diese SDK kann jederzeit unter \footnote{http://blogs.oracle.com/nike/entry/python\_api\_to\_the\_virtualbox} nachinstalliert werden.
\paragraph{config.csv}
In der "`config.csv"'-Datei, werden die Prozesse/Tests abgespeichert, welche bei einem Testdurchlauf abgehandelt werden. Aufbauend auf den Kommandos der Enum-Klasse, werden dort die Kommandos, welche im Abschnitt \ref{command} genauer beschrieben werden abgespeichert. Der Vorteil des gewählten CSV-Formats ist, dass es einerseits mit Tabellenkalukulationsprogrammen, die dieses Format zumeist unterstützen, andererseits mit einem einfachen Editor verändert werden kann.
\paragraph{Test}
Die Klasse Test ist eine abstrakte Klasse und beschreibt nur die Funktionen und Variablen, welche allen Subtests zur Verfügung stehen müssen. Es wird zum Beispiel allgemein für jede Art von Test Membervariablen wie "`start"' (die Startzeit des Tests), "`path"' (den Pfad zum CSV-Dokument mit den Daten), oder ein Socket-Objekt für die Kommunikation mit dem Host bei gewissen Tests erzeugt. Um später ein Kompositum aus den inzelnen Tests zu entwickeln, wurden auch die Funktionen zum Erzeugen von CPU-, HD- und Netzwerklast in dieser Klasse definiert. Der Aufruf für diese erfolgt allerdings erst in der Sub-Klasse.
Die Ergebnisse der einzelnen Subtests werden in einer CSV-Datei gespeichert und haben folgende Stuktur, wobei gilt $i=Iteration$:
\begin{lstlisting}
NewTest, <Test type>, <Client name>
Number of i <int>, Duration of i <float>, Starttime of i <float>
.
.
EndTest
\end{lstlisting}
\subsubsection{Tests}\label{test}
\paragraph{Mattest}
Beim Mattest geht es darum den/die Prozessorkern(e) mit einer Rekursion möglichst auszulasten. Dies wird beim Mattest erreicht, indem die in der Informatik häufig gebrauchte Fibonacci-Folge zu berechnen, welche folgendermaßen definiert ist:
	\[
	f_{n}=f_{n-1}+f_{n-2}
\]
für $n\geq2$. Des weiteren gilt $f_{0}=0$ und $f_{1}=1$.
Diese Funktion kann man relativ übersichtlich in Python rekursiv beschreiben und kommt zu folgendem Ergebnis:
\begin{lstlisting}
    def fib(self, n):
        if n <= 0:
            return 0
        elif n == 1:
            return 1
        else:
            return self.fib(n-1) + self.fib(n-2)
\end{lstlisting}
Der Rechenaufwand steigt mit größer werdendem $n$ exponentiell und somit auch die Laufzeit, weshalb dies Funktion bestens für diesen Test geeignet ist.
\paragraph{I-O}
Beim I/O-Test wird eine Datei einer gewissen Größe (bei meinen Tests 20MB) geöffnet und danach eingelesen. Der eingelesene Inhalt wird sofort danach wieder in ein andere Datei geschrieben. Es entstehen hier größere Lasten am Prozessor und bei der Festplatte. Die Realisierung sieht folgendermaßen aus:
\begin{lstlisting}
    def IO(self):
        o = open('lorem.txt', 'r')
        data = o.read()
        i = open('temp.txt', 'w')
        i.write(str(data))
        o.close()
        i.close()
\end{lstlisting}
\paragraph{SeekAndWrite}
Dieser Test ähnelt dem zuvor genannten I/O-Test. Es wird hier wiederum eine Datei, welche diesmal wesentlich größer dimensioniert (in meinem Fall 2,5GB) ist, geöffnet und nach einem gewissen String-Muster gesucht, welches vom Host bei der jeweiligen Iteration mitgeliefert wurde. Nun ist es Aufgabe des Tests die Datei zu öffnen und nach diesem Teilstring zu suchen. Wurde er gefunden, so muss zu dem Index gesprungen werden und der Teilstring von der Datei plus einer gewissen Anzahl an Zeichen, welche darauf folgen in eine andere temporäre Datei geschrieben werden.
Der Suchalgorithmus wurde folgendermaßen implementiert.
\begin{lstlisting}
    def seek(self, s):
        o = open('lorem1.txt', 'r')
        
        lastString = ''
        while True:
            currentString = o.read(self.enum.chunkSize)
            lastString = lastString + currentString
            index1 = lastString.find(s)
            if index1 > 0:
                index1 = o.tell()+index1-(2*self.enum.chunkSize)
                break
            else:
                lastString = currentString
\end{lstlisting}
\paragraph{TCP}
Der TCP-Test ist ein Netwerktest und ist folgendermaßen aufgebaut. Nachdem der Client den Befehl zum Start des Tests bekommen hat, wird vom Host ein Socket geöfnet. Der Client versucht sich dorthin via TCP zu verbinden und schickt einen Teststring an den Host. Danach wird die Verbindung wieder abgebaut. Pro Iteration wird dieser Vorgang mehrere Male wiederholt, um auf eine annähernd messbare Größe zu kommen. Der zugehörige Auszug aus dem Source-Code für den Verbindungsaufbau sieht folgendermaßen aus:
\begin{lstlisting}
    def TCP (self, message, serverIP, port):
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        s.connect((serverIP, port))
        s.send(message)
        if message == self.enum.stop:
            while True:
                data = s.recv(512)
                if data:
                    break
        s.close()
\end{lstlisting}

\newpage
\section{Testfälle}
\subsection{Allgemeine Beschreibung}
Das Entwickeln der Tests lief prinzipiell in zwei Phasen ab. Zuerst wurde ein entwickelter Test nativ, also nicht in einer VM, getestet. Hier lief in derselben Windows 7-Umgebung sowohl der Host, als auch der Client. Auf den virtualisierten Teil wurde anfangs immer verzichtet. War der Test für einen und später für mehrere Clients auf diesem nativen System stabil genug, so wurde das Testframework in der zweiten Phase auf eine Testumgebung portiert, um dort ausführlichere Testungen durchführen zu können.

Die Testumgebung für die unten angeführten Tests besteht (sofern nicht anders angeführt) aus einem "`AMD Athlon(tm) 64 X2 Dual Core Processor 5000+"', mit 3GB Hauptspeicher. Als Betriebssystem wurde sowohl für das Host-System, als auch für die VMs die Linux-Distribution "`Ubuntu"' in der Version 11.04 verwendet. Anzumerken ist ebenso, dass im Host-Betriebssystem eine 64Bit-Variante und in den Guest-Betriebssystemen eine 32Bit-Variante gewählt wurde. Als VMM kam VirtualBox von der Firma Oracle in der Version 4.1.2 zum Einsatz. Als Testmaschinen wurden bis zu vier, durch klonen, baugleiche Virtuelle Maschinen verwendet. Diese verfügten entweder über 256MB oder 128MB Arbeitsspeicher und es wurde ihnen eine 10GB-Festplatte von fixer Größe zugewiesen. Ebenfalls wurde der Host des Frameworks immer im Host-Betriebssystem ausgeführt und nie irgendwo anders, also remote oder innerhalb einer virtuellen Maschine.
\subsection{Fortschreitende Ergebnisse}

\newpage
\section{Zukunftspläne}
\subsection{Dokumentation}
Um das Framework auch außenstehenden zur Verfügung zu stellen, wäre es noch gut eine Dokumentation außerhalb des Codes und dieser Arbeit anzufertigen. Es würde sich hierführ wahrscheinlich "`Sphynx - Python Document Generator"'\footnote{http://sphinx.pocoo.org/} anbieten, mit dem auch die reguläre Dokumentation von Python gemacht wird.
\subsection{Messkampagnen und Messstrategien}
In den bis jetzt ausgeführten Tests wurde ausschließlich die Größe des Hauptspeichers variiert. Natürlich gibt es hier mehrere Variablen denen man seine Aufmerksamkeit schenken könnte. Man könnte beispielsweise genauso die virtuelle Prozessorleistung variieren, beziehungsweise Restriktionen für den Netzwerkverkehr setzten, um herauszufinden, ob der VMM in diesen Fällen immer noch fair agiert.
\subsection{Ansteuerung des Hypervisors}
Um das Durchführen von den zuvor genannten Messkampagenen und -strategien möglichst effizient durchsetzten zu können, wäre das Ansteuern des VMM zwischen einzelnen Tests noch eine wichtige Komponente. Somit wäre es zum Beispiel möglich einen Test zu starten und nach dessen Beendigung die Konfiguration des VMM zu verändern und den Test erneut zu starten.
\subsection{Weitere Tests}
Auch die Eingliederung von neuen Tests in das Framework wäre eine Bereicherung für ebendieses. Die Art und Weise, wie dieser zu erstellen ist wird im Anhang \ref{myTest} genauer beschrieben. Die Bandbreite von noch zu erstellenden Tests ist denkbar groß, so könnten beispielsweise diverse spezifische Komponententests implementiert werden, oder auch die bistehenden noch erweitert werden.
\subsection{Vergleich nativer und virtualisierter Tests}
Prinzipiell besteht ebenfalls die Möglichkeit, neben den virtualisierten Messungen ebenfalls welche auf nativen Systemen durchzuführen. Hier müssen allerdings die Voraussetzungen passen und es sollten gleiche Maschinen verwendet werden. Eine andere Überlegung wäre, während der virtualisierten Tests einen Test nativ laufen zu lassen. Heikel wird es hier allerdings bei der Interpretation der Ergebnisse, denn es ist unmöglich die gewonnen Messdaten im nativen System direkt als Referenzwert zu verwenden.

\newpage
\section{Schluss}

\begin{appendix}
\newpage
\section{Lessons lerned}
\subsection{Portierung}
Ein gewisses Problem hat die Portierung von einem Betriebssystem auf ein anderes dargestellt. Man musste während der Entwicklung immer genau darauf achten, dass der Source-Code auf gängigen Betriebssystemen reibungsfrei läuft. In meinem Fall hat es neben ein paar Kleinigkeiten auch einmal ein etwas größeres Problem gegeben. Beim TCP-Test war der ursprüngliche Code so beschaffen, dass ein Socket-Objekt initialisiert und danach verwendet wird, was folgendermaßen ausgesehen hat:
\begin{lstlisting}
	s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
	s.connect((serverIP, port))
	s.send(message)
\end{lstlisting}
Dieser Aufruf geschieht mehrere Male in Folge und unter dem Betriebssystem "`Windows 7"' hat dies ohne Tadel geklappt. Als es dann zur Portierung auf einen Ubuntu-Rechner gekommen ist, wurde permanent eine Exception geworfen. Der Grund stellt sich als folgender heraus. Unter Ubuntu kann man ein und das selbe Socket standardmäßig nicht mehrmalig hintereinander verwenden. Es bedarf einer Änderung in den Optionen des Sockets, welche zwar durch eine einzige Zeile erledigt werden kann, aber der Grund dafür mühsam herauszufinden war. Mit der Option
\begin{lstlisting}
	s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
\end{lstlisting}
hat der TCP-Test auch unter Ubuntu richtig funktioniert.

\subsection{Expect the unexpected}
In einem sehr frühen Stadium des Frameworks wurden Tests durchgeführt. Das Ergbnis war ziemlich interessant, denn es scheinte sich eine gewisse Präferenz einer VM abzuzeichnen. Doch schnell war ein möglicher Grund für dieses Verhalten gefunden, nämlich die Reihenfolge in welcher die virtuellen Maschinen gestartet wurden. Allerdings war es mir im Nachhinein nicht mehr möglich diese Reihenfolge zu rekonstruieren und so sank die Wertigkeit der Testmessung im selben Moment. Ein unerwartetes Ereignis führte also dazu, dass man nochmals von Vorne beginnen konnte. Herr über das Unerwartete zu werden ist denkbar schwierig, einzig und allein eine stetige Dokumentation von Arbeitsschritten, die im ersten Moment noch unwichtig erscheinen mögen, könnte so ein Vorkommen abwenden.

\subsection{Synchronizität}
Es ist ein denkbar schmaler Grad im Bereich der Synchronität. Einerseits versucht man alles so synchron als möglich zu halten, andererseits gibt es keine absolute Synchronität. Es ist natürlich notwendig die Abläufe in einem Test möglichst synchron zu halten, allerdings kann es auch sein, dass man durch "`übertriebene Genauigkeit"' sein eigenes Testergebnis verfälscht. Beispielsweise versucht man nur einen TCP-connect von mehreren Maschinen synchron ablaufen zu lassen, so wird der Fehler in der Zeitnehmung vielleicht sogar größer sein, als die genommene Zeit. Während eine der virtuellen Maschinen noch nicht mal den Befehl zum Connect erhalten hat, hat die andere ihr Pensum bereits durchlaufen. 

Aber auch in die gegenteilige Richtung ist die Synchronität nicht immer schwer zu handhaben. Nimmt man hier zum Beispiel eine sehr große Anzahl an Connects, so kann es passieren, dass eine virtuelle Maschine schon lange fertig ist, während die andere noch eine sehr große Zahl an Connects vor sich hat. Die Belastung ist demnach nicht mehr dieselbe, weshalb die Ergebnisse, wo nur mehr eine VM arbeitet eigentlich zu ignorieren wären.

Aus diesem Grund wurde in dem Framework die Größe der Iteration eingeführt. Man versucht die Laufzeiten einer Iteration so zu wählen, dass die beiden oben genannten Erscheinungen nur vernachlässigbare Nebeneffekte sind und diese Messdaten dann auszuwerten.

\section{Eigene Testklasse erstellen}\label{myTest}
Um eine eigene Testklasse für das Framework zu erstllen, müssen einige Dinge befolgt werden, um vernünftige Ergebnisse zu erziehlen. Die Klasse \textit{UserTest} sollte immer eine Sub-Klasse der Klasse \textit{Test} sein, damit ihr die richtigen Membervariablen und Funktionen zur Verfügung stehen. Braucht man jetzt noch zusätzliche Membervariablen, können diese an erster Stelle deklariert werden. Die Klasse \textit{UserTest} braucht zumindest eine Funktion mit dem Namen \textit{startUser(self)}, welche von der \textit{Client}-Instanz aufgerufen werden kann. Dort findet der eigentliche Testablauf statt. Die Funktion muss folgendermaßen aufgebaut sein:
\begin{lstlisting}
class UserTest(Test):

    def startUser(self):
				self.initTest()
        
        while True:
            i = self.recieve()
            if i[0] == self.enum.iteration:
                start = time.time()
                \textit{UserTestFunction()}
                dur = time.time() - start
                values = [str(i[1]), str(dur), str(start)]
                self.results.writerow(values)
            if i[0] == self.enum.stop:
                break
            
        self.endTest()
\end{lstlisting}
Was hier passiert kann folgendermaßen veranschaulicht werden:
\begin{itemize}
	\item Zeile 4: Der Test wird initalisiert. Es stehen für den eigens kreierten Test folgende Variablen zur Verfügung, die verwendet werden können, allerdings natürlich nicht müssen:
	\begin{itemize}
		\item \textit{self.path}: Der FileObject zu der CSV-Datei, in welcher alle Daten dieser Testserie gespeichert werden.
		\item \textit{self.serverIP}: Die IP-Adresse des Servers, zu dem man verbunden ist, als String gespeichert.
		\item \textit{self.port}: Der Port des Servers, zu dem man verbunden ist, als String gespeichert.
		\item \textit{self.enum}: Eine Objekt der Klasse \textit{Enum}, um auf die Kommunikationsbefehele Zugriff zu haben.
		\item \textit{self.init}: Die Zeit gemessen via time.time() in Zeile 4 des Aufrufes \textit{startUser}
		\item \textit{self.start}: Eine Variable zum Speichern der Startzeit einer Iteration.
		\item \textit{self.dur}: Eine Variable zum Speichern der Laufzeit einer Iteration.
	\end{itemize}
	\item Zeile 6ff.: Um adequat die einzelnen Iterationen gleichzeitig mit allen anderen virtuellen Maschinen durchführen zu können, ist dieses Schleifenkonstrukt notwendig. Prinzipiell kann man dieses folgend beschreiben. Zuerst wird eine Verbindung mit dem \textit{Host} aufgebaut und eine Nachricht wird entgegengenommen. Diese ist zweiteilig und enthält entweder \textit{i[0]=Befehl zur Iteration, i[1]=Nummer der Iteration} oder\textit{ i[0]=Befehl zur Beendigung, i[1]=0}.
	\item Zeile 8, 14: In den If-Abfragen wird zwischen diesen beiden Fällen unterschieden und entweder der Code zum Testen ausgeführt, oder die Schleife terminiert.
	\item Zeile 9-13: Dies ist ein Vorschlg für die Zeitnehmung und das Abspeichern der Daten. Der Ablauf muss natürlich nicht genauso sein, es empfiehlt sich aber einen ähnlichen Ablauf einzuhalten. Tut man dies, so können anschließend automatisch Graphen und gewisse statistische Werte mit der Klasse Results berechnet werden. Zusätzlich ist noch anzumerken, dass in Zeile 12 und 13 nicht zwingendermaßen die Nummer der Iteration, die Laufzeit der Iteration und die Startzeit der Iteration abgespeichert werden müssen. Allgemeiner könnte man diese Zeilen wahrscheinlich als
\begin{lstlisting}
values = [str(Graph_X_Value), str(Graph_Y_Value), str(AnyValue)]
self.results.writerow(values)
\end{lstlisting}
beschreiben. Es ist also wichtig dass an der ersten stelle der x-Wert dessen, was später im Graph angezeigt werden soll steht und an zweiter Stelle der y-Wert. Der dritte Wert ist nicht entscheidend und dient nur dazu, um zum Beispiel eine weitere Messgröße ebenfalls zu loggen. Sie wird allerdings beim Erstellen der Graphen nicht berücksichtigt.
\item Zeile 17: Die Methode \textit{startUser} sollte zuletzt noch mit der Methode \textit{self.endTest()} finalisiert werden. Hier werden noch Kleinigkeiten in die CSV-Datei geschrieben und weiters die Variablen freigegeben.
\end{itemize}
Um selbst weitere Tests im Bereich der Netzwerkauslastung zu erstellen, muss man dafür seinen eigenen Server definieren, da nicht allgemein gewährleistet werden kann, dass jeder Testaufbau in diesem Fall analog ist. Zum Beispiel kann es zu einer gewollten Vertauschung von socket.recv() und socket.send() auf Server- und Clientseite kommen, was im Voraus in diesem Framework natürlich nicht berücksichtigt werden kann.
\end{appendix}
\bibliography{Template}
\end{document}